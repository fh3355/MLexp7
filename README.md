# lab7
实验七-基于序列模型的中英文翻译机

- 成功运行完整的代码流程，包括数据处理、模型训练和评估，并理解各部分代码模块的功能
    
- 生成并保存模型训练过程中的损失变化曲线，并作相关记录
    
- 使用 BLEU 指标评估训练后模型的翻译性能
    
    ```
      # pip install nltk
      from nltk.translate.bleu_score import sentence_bleu
      bleu_score = sentence_bleu([reference1, reference2, reference3], hypothesis1)
    ```
    
    选择几个测试句子，输出模型的翻译结果，并与原始标签进行对比。同时，调用 showAttention 函数，将注意力权重矩阵可视化成热力图，直观分析模型的翻译过程。
    
- 复现展示可视化的注意力权重矩阵，并结合具体翻译案例，简要分析其工作原理
    
- 思考： normalizeString 函数中的正则表达式是为英文设计的，直接用于处理中文是否会产生问题？应如何调整以正确处理中文句子？
    

**注意！！**

- 在训练过程中请大家将中间结果（例如loss值、翻译评估指标等）保存为文件，例如使用csv包将loss数组保存为csv文件，方便后续重绘loss值曲线。同时保存模型权重以便测试翻译效果。否则重新训练时间成本较大。
- 模型训练算力消耗较大，同学们可调小batch size，并且没必要按照示例程序训练全部epoch。训练部分的目的在于理解程序运行过程而非得到最终模型。
- 本次实验将使用JetAutoML平台，使用过程中需要将结果(loss曲线等)上传到平台上，平台可直接可视化结果。因此需要在结果生成处添加少量代码以完成结果上传。具体使用方法待定。

**实验参考步骤**

1.  数据加载：分析 readLangs 函数，理解如何读取 eng-cmn.txt 并生成句子对。
2.  文本规范化：重点修改 normalizeString 函数中的正则表达式，确保其能正确处理中文句子（提示：中文句子应按字进行分割，而不是移除）。
3.  词典创建：通过 Lang 类为输入（中）和输出（英）语言构建词典。
4.  模型定义：分别阅读并理解 EncoderRNN 和 AttnDecoderRNN 两个类的代码实现。
5.  训练：运行 trainIters 函数启动模型训练。可适当调小 n_iters 以缩短训练时间。
6.  评估：运行 evaluateRandomly 函数，查看随机翻译样本的效果并获取平均 BLEU 分数。
7.  可视化：使用 showPlot 函数绘制损失曲线，使用 evaluateAndShowAttention 函数展示具体翻译案例的注意力分布。